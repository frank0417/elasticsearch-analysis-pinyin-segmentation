package org.elasticsearch.index.analysis.pinyin.utils;import org.elasticsearch.common.collect.ImmutableMap;import org.elasticsearch.common.collect.ImmutableSet;import org.elasticsearch.common.collect.Lists;import org.elasticsearch.index.analysis.pinyin.entity.TokenEntity;import java.util.List;import java.util.Set;public class OverlapAmbiguitySolver {    static ImmutableSet<Character> endChar = ImmutableSet.of(            'g', 'n', 'r', 'a'    );    static ImmutableSet<Character> startChar = ImmutableSet.of(            'a', 'e', 'i', 'o', 'u'    );    static ImmutableSet<Character> forbiddenCharOfA = ImmutableSet.of(            'a', 'e', 'u'    );    // if the overlap ambiguity is hit in this map, do not add to the final result    // always the high-frequency phrase are contained such as "jing an" that always refers to "静安" while "jin gan" has no meaning    // TODO generate this set by auto-training, such as calculating the appearance    // TODO or use a bi-gram/tri-gram model to predict the likelihood    static ImmutableMap<String, Set<String>> ignorance = ImmutableMap.<String, Set<String>>builder()            .put("jing", ImmutableSet.of("an"))            .build();    // TODO add the overwrite set for example that "yingou" is always split to "yin gou" but rare "ying ou"    public static List<TokenEntity> solve(List<TokenEntity> input) {        if (input.size() <= 1) {            return input;        }        List<TokenEntity> ambiguities = Lists.newArrayList();        for (int i=0; i<input.size()-1; i++) {            TokenEntity formerToken = input.get(i);            // if the pair hits the ignorance set, just ignore the ambiguity            if (ignorance.containsKey(formerToken.getValue()) &&                    ignorance.get(formerToken.getValue()).contains(input.get(i+1).getValue())) {                continue;            }            String former = formerToken.getValue();            char lastCharOfFormer = former.charAt(former.length()-1);            if (endChar.contains(lastCharOfFormer)) {                TokenEntity latterToken = input.get(i+1);                String latter = latterToken.getValue();                char firstCharOfLatter = latter.charAt(0);                if (startChar.contains(firstCharOfLatter)) {                    if (lastCharOfFormer != 'a' || !forbiddenCharOfA.contains(firstCharOfLatter)) {                        ambiguities.add(formerToken.duplicate()                                .setValue(former.substring(0, former.length() - 1))                                .setEndOffset(formerToken.getEndOffset() - 1));                        ambiguities.add(latterToken.duplicate()                                .setValue(former.charAt(former.length() - 1) + latter)                                .setBeginOffset(latterToken.getBeginOffset() - 1));                    }                }            }        }        input.addAll(ambiguities);        return input;    }}